<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Strategies and equilibria on selected markets: a multi-agent simulation and stochastic modeling approach | Aldric Labarthe</title>
<meta name="keywords" content="Reinforcement Learning, Agent-based models, Econo-physics, algorithmic collusion">
<meta name="description" content="In this paper, we introduce the first agent-based model of competition in quantities featuring a *Deep Deterministic Policy Gradient* (DDPG) algorithm and assess its effect on both equilibrium stability and collusive outcome.">
<meta name="author" content="Aldric Labarthe">
<link rel="canonical" href="https://example.org/papers/mir/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.d11d335b4a0d8ab2f0e140b924b76d1e32c09eb57deaeb4a5fb2c155579c07a9.css" integrity="sha256-0R0zW0oNirLw4UC5JLdtHjLAnrV96utKX7LBVVecB6k=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://example.org/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://example.org/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://example.org/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://example.org/apple-touch-icon.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://example.org/papers/mir/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:title" content="Strategies and equilibria on selected markets: a multi-agent simulation and stochastic modeling approach" />
<meta property="og:description" content="In this paper, we introduce the first agent-based model of competition in quantities featuring a *Deep Deterministic Policy Gradient* (DDPG) algorithm and assess its effect on both equilibrium stability and collusive outcome." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://example.org/papers/mir/" />
<meta property="og:image" content="https://example.org/actorCriticSummary.png" /><meta property="article:section" content="papers" />
<meta property="article:published_time" content="2024-05-22T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-11-22T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://example.org/actorCriticSummary.png" />
<meta name="twitter:title" content="Strategies and equilibria on selected markets: a multi-agent simulation and stochastic modeling approach"/>
<meta name="twitter:description" content="In this paper, we introduce the first agent-based model of competition in quantities featuring a *Deep Deterministic Policy Gradient* (DDPG) algorithm and assess its effect on both equilibrium stability and collusive outcome."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Papers",
      "item": "https://example.org/papers/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Strategies and equilibria on selected markets: a multi-agent simulation and stochastic modeling approach",
      "item": "https://example.org/papers/mir/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Strategies and equilibria on selected markets: a multi-agent simulation and stochastic modeling approach",
  "name": "Strategies and equilibria on selected markets: a multi-agent simulation and stochastic modeling approach",
  "description": "In this paper, we introduce the first agent-based model of competition in quantities featuring a *Deep Deterministic Policy Gradient* (DDPG) algorithm and assess its effect on both equilibrium stability and collusive outcome.",
  "keywords": [
    "Reinforcement Learning", "Agent-based models", "Econo-physics", "algorithmic collusion"
  ],
  "articleBody": " Download Thesis and mathematical appendices Code and simulator Defense (slides) Abstract In this paper, we introduce the first agent-based model of competition in quantities featuring a Deep Deterministic Policy Gradient (DDPG) algorithm. This algorithm has been selected as a replacement for the traditional Q-Learning algorithm to examine two current unsolved questions in the economic literature: the tendency of algorithmic markets to converge toward a collusive equilibrium, and the chaotic behavior of the dynamic Cournot oligopoly. We show that the DDPG algorithm is a relevant tool to model oligopolies with independent learning agents. We find that our model consistently converges toward the Nash-equilibrium in every market structure we have tested, except for the Cournot oligopoly with well-tuned parameters. We estimate the effect of these parameters on the decision process and explain why collusion may occur in this situation. Overall, we show that algorithmic collusion remains an exception when algorithmic complexity increases. We also place our model in chaotic settings and find that the chaotic behavior of the dynamic Cournot model was only theoretical and never observed in simulations.\nResearch evolution This work is my master thesis for my master’s degree at Ecole Normale Supérieure de Paris-Saclay (France). I’m currently working with Pr. Julien Randon-Furling to improve the thesis and rewrite it as a journal paper.\nFigure 1: Our RL-algorithm design Figure 2: Our simulations have not necessarily shown collusive behaviors Figure 3: Collusion is not entirely determined by the trade-off present exploitation-future rewards Citation @mastersthesis{Labarthe_2024, author = {Aldric Labarthe}, date-added = {2024-04-22 16:42:42 +0200}, school = {Ecole Normale Sup{\\'e}rieure Paris-Saclay}, title = {Strategies and equilibria on selected markets: a multi-agent simulation and stochastic modeling approach}, year = {2024}} ",
  "wordCount" : "277",
  "inLanguage": "en",
  "image":"https://example.org/actorCriticSummary.png","datePublished": "2024-05-22T00:00:00Z",
  "dateModified": "2024-11-22T00:00:00Z",
  "author":[{
    "@type": "Person",
    "name": "Aldric Labarthe"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://example.org/papers/mir/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Aldric Labarthe",
    "logo": {
      "@type": "ImageObject",
      "url": "https://example.org/favicon.ico"
    }
  }
}
</script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" integrity="sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js" integrity="sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          delimiters: [
            {left: '$$', right: '$$', display: true},
            {left: '$', right: '$', display: false},
            {left: "\\begin{equation}", right: "\\end{equation}", display: true},
            {left: "\\begin{equation*}", right: "\\end{equation*}", display: true},
            {left: "\\begin{align}", right: "\\end{align}", display: true},
            {left: "\\begin{align*}", right: "\\end{align*}", display: true},
            {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
            {left: "\\begin{gather}", right: "\\end{gather}", display: true},
            {left: "\\begin{CD}", right: "\\end{CD}", display: true},
          ],
          throwOnError : false
        });
    });
</script>
 


</head>

<body class="" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://example.org/" accesskey="h" title="Aldric Labarthe">
                <img src="https://example.org/PDP.jpg" alt="" aria-label="logo"
                    height="18"
                    width="18">Aldric Labarthe</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://example.org/papers/" title="Papers">
                    <span>Papers</span>
                </a>
            </li>
            <li>
                <a href="https://example.org/courses/" title="Courses">
                    <span>Courses</span>
                </a>
            </li>
            <li>
                <a href="https://example.org/projects/" title="Miscellaneous projects">
                    <span>Miscellaneous projects</span>
                </a>
            </li>
            <li>
                <a href="https://example.org/archive/" title="All by dates">
                    <span>All by dates</span>
                </a>
            </li>
            <li>
                <a href="https://example.org/tags/" title="All by tags">
                    <span>All by tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Strategies and equilibria on selected markets: a multi-agent simulation and stochastic modeling approach
    </h1>
    <div class="post-meta"><span title='2024-05-22 00:00:00 +0000 UTC'>May 2024</span>&nbsp;&middot;&nbsp;Aldric Labarthe

</div>
  </header> 
  <div class="post-content"><hr>
<h5 id="download">Download</h5>
<ul>
<li><a href="https://github.com/Aldric-L/DDPG-Oligopolies-Simulator/blob/main/Strategies%20and%20equilibria%20on%20selected%20markets.pdf" target="_blank">Thesis and mathematical appendices</a></li>
<li><a href="https://github.com/Aldric-L/DDPG-Oligopolies-Simulator" target="_blank">Code and simulator</a></li>
<li><a href="DefenseALABARTHE.pdf">Defense (slides)</a></li>
</ul>
<!--+ [Data](https://1drv.ms/f/s!An5zxDZ6MkIwo4JOOjl38hN-FeKA-A?e=pnTXqT)-->
<hr>
<h5 id="abstract">Abstract</h5>
<p>In this paper, we introduce the first agent-based model of competition in quantities featuring a <em>Deep Deterministic Policy Gradient</em> (DDPG) algorithm. This algorithm has been selected as a replacement for the traditional Q-Learning algorithm to examine two current unsolved questions in the economic literature: the tendency of algorithmic markets to converge toward a collusive equilibrium, and the chaotic behavior of the dynamic Cournot oligopoly. We show that the DDPG algorithm is a relevant tool to model oligopolies with independent learning agents. We find that our model consistently converges toward the Nash-equilibrium in every market structure we have tested, except for the Cournot oligopoly with well-tuned parameters. We estimate the effect of these parameters on the decision process and explain why collusion may occur in this situation. Overall, we show that algorithmic collusion remains an exception when algorithmic complexity increases. We also place our model in chaotic settings and find that the chaotic behavior of the dynamic Cournot model was only theoretical and never observed in simulations.</p>
<hr>
<h5 id="research-evolution">Research evolution</h5>
<p>This work is my master thesis for my master&rsquo;s degree at Ecole Normale Supérieure de Paris-Saclay (France). I&rsquo;m currently working with Pr. Julien Randon-Furling to improve the thesis and rewrite it as a journal paper.</p>
<hr>
<h5 id="figure-1-our-rl-algorithm-design">Figure 1: Our RL-algorithm design</h5>
<p><img loading="lazy" src="/papers/mir/actorCriticSummary.png"></p>
<h5 id="figure-2-our-simulations-have-not-necessarily-shown-collusive-behaviors">Figure 2: Our simulations have not necessarily shown collusive behaviors</h5>
<p><img loading="lazy" src="/papers/mir/Cournot2Gamma0-TotalQty.png"></p>
<h5 id="figure-3-collusion-is-not-entirely-determined-by-the-trade-off-present-exploitation-future-rewards">Figure 3: Collusion is not entirely determined by the trade-off present exploitation-future rewards</h5>
<p><img loading="lazy" src="/papers/mir/Cournot2GammaDelta.png"></p>
<hr>
<h5 id="citation">Citation</h5>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-BibTeX" data-lang="BibTeX"><span style="display:flex;"><span><span style="color:#a6e22e">@mastersthesis</span>{Labarthe_2024,
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">author</span> = <span style="color:#e6db74">{Aldric Labarthe}</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">date-added</span> = <span style="color:#e6db74">{2024-04-22 16:42:42 +0200}</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">school</span> = <span style="color:#e6db74">{Ecole Normale Sup{\&#39;e}rieure Paris-Saclay}</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">title</span> = <span style="color:#e6db74">{Strategies and equilibria on selected markets: a multi-agent simulation and stochastic modeling approach}</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">year</span> = <span style="color:#e6db74">{2024}</span>}
</span></span></code></pre></div><!-----

##### Related material

+ [Presentation slides](presentation2.pdf)
+ [Wikipedia entry](https://en.wikipedia.org/wiki/The_Finer_Points_of_Sausage_Dogs)-->

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://example.org/tags/reinforcement-learning/">Reinforcement Learning</a></li>
      <li><a href="https://example.org/tags/agent-based-models/">Agent-Based Models</a></li>
      <li><a href="https://example.org/tags/econo-physics/">Econo-Physics</a></li>
      <li><a href="https://example.org/tags/algorithmic-collusion/">Algorithmic Collusion</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://example.org/">Aldric Labarthe</a></span> ·     
    <span>
    Powered by 
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/pmichaillat/hugo-website/" rel="noopener" target="_blank">a modified version</a>
         of 
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>
</html>
